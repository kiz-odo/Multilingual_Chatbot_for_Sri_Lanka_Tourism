# Prometheus Alert Rules
# Configure alerting for critical system events

groups:
  - name: application_alerts
    interval: 30s
    rules:
      # High Error Rate
      - alert: HighErrorRate
        expr: |
          rate(errors_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec for the last 5 minutes"
          
      # High Response Time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High API response time"
          description: "95th percentile response time is {{ $value }}s"
      
      # Database Connection Issues
      - alert: DatabaseConnectionLow
        expr: |
          db_connections_active < 5
        for: 2m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Low database connections"
          description: "Only {{ $value }} database connections active"
      
      # Rate Limit Abuse
      - alert: RateLimitAbuse
        expr: |
          rate(rate_limit_exceeded_total[5m]) > 50
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High rate limit violations"
          description: "{{ $value }} rate limit violations/sec detected"
      
      # Cache Hit Ratio Low
      - alert: LowCacheHitRatio
        expr: |
          cache_hit_ratio < 0.5
        for: 10m
        labels:
          severity: info
          team: backend
        annotations:
          summary: "Low cache hit ratio"
          description: "Cache hit ratio is {{ $value }}"

  - name: infrastructure_alerts
    interval: 60s
    rules:
      # Service Down
      - alert: ServiceDown
        expr: |
          up{job="backend"} == 0
        for: 2m
        labels:
          severity: critical
          team: ops
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "Backend service has been down for more than 2 minutes"
      
      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}%"
      
      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}%"
      
      # Disk Space Low
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 15
        for: 10m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Only {{ $value }}% disk space remaining"

  - name: business_alerts
    interval: 60s
    rules:
      # No New Users
      - alert: NoNewUserRegistrations
        expr: |
          increase(users_registered_total[1h]) == 0
        for: 2h
        labels:
          severity: info
          team: business
        annotations:
          summary: "No new user registrations"
          description: "No users have registered in the last 2 hours"
      
      # High Chat Latency
      - alert: HighChatLatency
        expr: |
          histogram_quantile(0.95, rate(chat_response_time_seconds_bucket[5m])) > 5
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High chat response latency"
          description: "95th percentile chat response time is {{ $value }}s"
      
      # LLM Errors
      - alert: HighLLMErrors
        expr: |
          rate(llm_requests_total{status="error"}[5m]) > 5
        for: 5m
        labels:
          severity: warning
          team: ai
        annotations:
          summary: "High LLM error rate"
          description: "LLM error rate is {{ $value }} errors/sec"

  - name: security_alerts
    interval: 30s
    rules:
      # Multiple Failed Login Attempts
      - alert: HighFailedLogins
        expr: |
          increase(http_requests_total{endpoint="/api/v1/auth/login",status="401"}[5m]) > 20
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High number of failed login attempts"
          description: "{{ $value }} failed login attempts in 5 minutes"
      
      # Suspicious Activity
      - alert: SuspiciousActivity
        expr: |
          rate(http_requests_total{status=~"4..|5.."}[5m]) > 50
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High rate of HTTP errors"
          description: "{{ $value }} error responses/sec detected"
